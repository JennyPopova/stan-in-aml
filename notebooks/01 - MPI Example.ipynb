{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Stan as MPI Job\n",
    "This notebook will submit Stan as an MPI Job. It's running the [`mpi_test.py`](../code/mpi_test.py) script. This script takes a pre-compiled Stan model and runs it as MPI. The [`compile_model.py`](../code/compile_model.py) script will compile the model.\n",
    "\n",
    "This example is based on the [Stan MPI Threading repo by Guido Biele](https://github.com/gbiele/Stan_MPI_Threading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Environment, ComputeTarget, Experiment, Dataset, Run\n",
    "from azureml.train.estimator import Estimator, Mpi\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate workspace and experiment objects\n",
    "ws = Workspace.from_config()\n",
    "stan_exp = Experiment(ws, 'stan-mpi-test')\n",
    "\n",
    "# Retrieve the Environment, ComputeTarget and Dataset objects.\n",
    "env = Environment.get(ws, 'stan-intelmpi')\n",
    "cpu_cluster = ComputeTarget(ws, 'cpu-cluster')\n",
    "\n",
    "# This dataset object is an AzureML FileDataset - which is pointing to the RDumps files \n",
    "# (generated from bbdata.R in the Stan_MPI_Threading repo) stored on Azure Blob Storage\n",
    "dataset = Dataset.get_by_name(ws, 'rdumps')\n",
    "\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_experiment(nodes, processes_per_node, samples=20000, test_id=None):\n",
    "    if not samples in [1000,5000,10000,20000,300000]:\n",
    "        raise AttributeError(f\"{samples} samples is not supported, please choose 1000, 5000, 10000, 20000, or 300000\")\n",
    "    \n",
    "    params = {'--data-path': dataset.as_named_input('input_files').as_mount(),\n",
    "              '--shared-model-datastore': datastore.as_mount(),\n",
    "              '--nodes': nodes, \n",
    "              '--procs': processes_per_node, \n",
    "              '--samples': samples,\n",
    "              '--stan-code-file': 'code/model/stan_model.stan'}\n",
    "    \n",
    "    mpi_estimator = Estimator(source_directory='..',\n",
    "                              entry_script='code/mpi_test.py',\n",
    "                              compute_target=cpu_cluster,\n",
    "                              node_count=nodes,\n",
    "                              distributed_training=Mpi(processes_per_node),\n",
    "                              environment_definition=env,\n",
    "                              script_params=params,\n",
    "                              max_run_duration_seconds=3600\n",
    "                      )\n",
    "    \n",
    "    tags = {'nodes': str(nodes), 'processes_per_node': str(processes_per_node), 'samples': str(samples)}\n",
    "    if test_id:\n",
    "        tags['test_id'] = str(test_id)\n",
    "    \n",
    "    run = stan_exp.submit(mpi_estimator, tags=tags)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_suite(nodes=[1, 2, 3, 4], procs=[1, 2, 4, 8, 16], samples=20000):\n",
    "    \"\"\"Loop through the passed nodes and procs lists and submit jobs\n",
    "       Passes a test_id to be used as a tag for experiment runs\n",
    "    \"\"\"\n",
    "    test_id = str(uuid4())\n",
    "    runs = []\n",
    "    for node in nodes:\n",
    "        for proc in procs:\n",
    "            runs.append(submit_experiment(nodes=node, \n",
    "                                          processes_per_node=proc, \n",
    "                                          test_id=test_id, \n",
    "                                          samples=samples))\n",
    "    return runs, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off the test suite\n",
    "runs = run_test_suite(samples=300000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(runs[0][0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess MPI Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = {20000: '[ENTER TEST ID]',\n",
    "            300000: '[ENTER TEST ID]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run(run):\n",
    "    sub_results = run.get_metrics()\n",
    "    sub_results['test_id'] = run.tags['test_id']\n",
    "    \n",
    "    return sub_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for samp_size in [20000,300000]:\n",
    "    for run in stan_exp.get_runs(tags={'test_id': test_ids[samp_size]}):\n",
    "        results.append(process_run(run))\n",
    "\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df['sample_size'] = results_df['samples'].apply(lambda x: \"20,000\" if x == 20000 else \"300,000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,10))\n",
    "\n",
    "sns.pointplot(x=\"shards\", y=\"process_time\",\n",
    "             hue=\"sample_size\",\n",
    "             data=results_df, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
